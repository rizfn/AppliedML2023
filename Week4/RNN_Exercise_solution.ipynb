{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN and Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN and Natural Language Processing\n",
    "\n",
    "In this exercise we will try to classify IMDB dataset: Given the text of a review, can you predict if the review was positive or negative?\n",
    "\n",
    "Before doing this exercise, you might want to become more familier with LSTMs by considering the example FlightPassengerPredictions.\n",
    "\n",
    "The data for this exercise can be found here:\n",
    "https://sid.erda.dk/share_redirect/encok5nw3y\n",
    "\n",
    "***\n",
    "\n",
    "Author: Julius Kirkegaard and Troels C. Petersen<br>\n",
    "Date: 14th of May 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from torch import nn\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_data = 10000  # limit the amount of data for speed, change as you please\n",
    "\n",
    "def remove_special_symbols(string):\n",
    "    return ''.join(s for s in string if ord(s)>96 and ord(s)<123 or s == ' ')\n",
    "\n",
    "with open('train.json') as f:\n",
    "    train_text, train_labels = json.load(f)\n",
    "    idxs = np.random.permutation(len(train_text))\n",
    "    train_text = [remove_special_symbols(train_text[i]) for i in idxs[:limit_data]]\n",
    "    train_labels = [train_labels[i] for i in idxs[:limit_data]]\n",
    "    \n",
    "with open('test.json') as f:\n",
    "    test_text, test_labels = json.load(f)\n",
    "    idxs = np.random.permutation(len(test_text))   \n",
    "    test_text = [remove_special_symbols(test_text[i]) for i in idxs[:limit_data]]\n",
    "    test_labels = [test_labels[i] for i in idxs[:limit_data]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data... Here is a negative review (label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es as the other reviewers have already stated this may not be vintage  but its far from being their worst work as at th entury tupid mean ox his film certainly has all of the basic ingredients for things to go wrong for the boys ut its their serious approach and determination that makes them funny hey dont play it for laughs as other comedians might but they take their work and situation quite seriously and that is the essence of their eternal humor n this film they are faced with some basic issues that really might be encountered by any one of us today namely job related stress irst we would get checked out by a doctor and he would prescribe some much needed rest and perhaps staying by the sea hats where the surrealness comes in to all of this  always take a most plausible set of circumstances and exaggerate it but never to the point of being incredible except maybe once in awhile his makes us laugh because we can relate to their self caused predicaments and attempts at extrication hats what makes tan and llie universal in their appeal n this film all those ingredients are presented in a delightfully artful and gracefully slapstick way ot their best in comparison to their earlier work probably because this was the actual last film they did for oach because he wanted to mirror the big studios and go into making features exclusively and also wanted to hurry up and finish their contractual obligation   hey should have all stayed together and continued for maybe five more years hat the world may have missed in their not considering this as an option atch laugh and enjoy this as their last great performance\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_text[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a positive one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aniel ay ewis is one of the best actors of our time and one of my favorites t is amazing how much he throws himself in each of the characters he plays making them realbr br  remember many years ago we had a party in our house  the friends came over we were sitting around the table eating drinking the wine talking laughing  having a good time he  was on  there was a movie which we did not pay much attention to hen suddenly all of us stopped talking and laughing he glasses did not clink the forks did not move the food was getting cold on the plates e could not take our eyes off the screen where the young crippled man whose entire body was against him and who only had a control over his left foot picked up a piece of chalk with his foot and for what seemed the eternity tried to write just one word on the floor hen he finished writing that one word we all knew that we had witnessed not one but three triumphs  the triumph of a human will and spirit the triumph of the cinema which was able to capture the moment like this on the film and the triumph of an actor who did not act but who became his characterbr br im heridans y eft oot is an riveting unsentimental biodrama about hristy rown the man who was born with cerebral palsy in a ublin slum who became an artist and a writer and who found a love of his lifebr br  like every one of ay ewiss performances  have mixed feelings about his performance in  but  believe that his greatest role was hristy rown in y eft oot\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_text[3])\n",
    "print(train_labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at all the words we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique words = 75375\n"
     ]
    }
   ],
   "source": [
    "all_words = list(chain(*[x.lower().split() for x in train_text]))\n",
    "print('total number of unique words =', len(set(all_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of words... of course, we could clean the data even more if we wanted to. But we won't...\n",
    "(for instance, there are probably many misspelled words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'es': 684,\n",
       "         'as': 17734,\n",
       "         'the': 117119,\n",
       "         'other': 3470,\n",
       "         'reviewers': 104,\n",
       "         'have': 11020,\n",
       "         'already': 523,\n",
       "         'stated': 52,\n",
       "         'this': 24254,\n",
       "         'may': 1221,\n",
       "         'not': 11062,\n",
       "         'be': 10681,\n",
       "         'vintage': 19,\n",
       "         'but': 13809,\n",
       "         'its': 7370,\n",
       "         'far': 1106,\n",
       "         'from': 8025,\n",
       "         'being': 2608,\n",
       "         'their': 4451,\n",
       "         'worst': 969,\n",
       "         'work': 1639,\n",
       "         'at': 8964,\n",
       "         'th': 318,\n",
       "         'entury': 52,\n",
       "         'tupid': 20,\n",
       "         'mean': 663,\n",
       "         'ox': 158,\n",
       "         'his': 17181,\n",
       "         'film': 15150,\n",
       "         'certainly': 538,\n",
       "         'has': 6620,\n",
       "         'all': 8564,\n",
       "         'of': 58258,\n",
       "         'basic': 184,\n",
       "         'ingredients': 41,\n",
       "         'for': 16827,\n",
       "         'things': 1444,\n",
       "         'to': 54078,\n",
       "         'go': 1807,\n",
       "         'wrong': 660,\n",
       "         'boys': 228,\n",
       "         'ut': 2983,\n",
       "         'serious': 394,\n",
       "         'approach': 143,\n",
       "         'and': 62860,\n",
       "         'determination': 18,\n",
       "         'that': 27264,\n",
       "         'makes': 1676,\n",
       "         'them': 3016,\n",
       "         'funny': 1627,\n",
       "         'hey': 1238,\n",
       "         'dont': 2984,\n",
       "         'play': 855,\n",
       "         'it': 26155,\n",
       "         'laughs': 252,\n",
       "         'comedians': 27,\n",
       "         'might': 1140,\n",
       "         'they': 7331,\n",
       "         'take': 1333,\n",
       "         'situation': 251,\n",
       "         'quite': 1424,\n",
       "         'seriously': 298,\n",
       "         'is': 43228,\n",
       "         'essence': 51,\n",
       "         'eternal': 26,\n",
       "         'humor': 527,\n",
       "         'n': 3036,\n",
       "         'are': 11624,\n",
       "         'faced': 51,\n",
       "         'with': 17349,\n",
       "         'some': 5784,\n",
       "         'issues': 182,\n",
       "         'really': 4436,\n",
       "         'encountered': 20,\n",
       "         'by': 8884,\n",
       "         'any': 3117,\n",
       "         'one': 9445,\n",
       "         'us': 1317,\n",
       "         'today': 348,\n",
       "         'namely': 35,\n",
       "         'job': 846,\n",
       "         'related': 67,\n",
       "         'stress': 42,\n",
       "         'irst': 376,\n",
       "         'we': 3172,\n",
       "         'would': 4813,\n",
       "         'get': 3650,\n",
       "         'checked': 26,\n",
       "         'out': 6514,\n",
       "         'a': 63108,\n",
       "         'doctor': 160,\n",
       "         'he': 27856,\n",
       "         'prescribe': 2,\n",
       "         'much': 3730,\n",
       "         'needed': 270,\n",
       "         'rest': 709,\n",
       "         'perhaps': 476,\n",
       "         'staying': 40,\n",
       "         'sea': 60,\n",
       "         'hats': 467,\n",
       "         'where': 2346,\n",
       "         'surrealness': 1,\n",
       "         'comes': 986,\n",
       "         'in': 35410,\n",
       "         'always': 1236,\n",
       "         'most': 3286,\n",
       "         'plausible': 37,\n",
       "         'set': 875,\n",
       "         'circumstances': 80,\n",
       "         'exaggerate': 7,\n",
       "         'never': 2508,\n",
       "         'point': 1167,\n",
       "         'incredible': 215,\n",
       "         'except': 392,\n",
       "         'maybe': 605,\n",
       "         'once': 752,\n",
       "         'awhile': 17,\n",
       "         'laugh': 498,\n",
       "         'because': 3466,\n",
       "         'can': 4442,\n",
       "         'relate': 90,\n",
       "         'self': 167,\n",
       "         'caused': 87,\n",
       "         'predicaments': 3,\n",
       "         'attempts': 241,\n",
       "         'extrication': 1,\n",
       "         'what': 5047,\n",
       "         'tan': 36,\n",
       "         'llie': 20,\n",
       "         'universal': 33,\n",
       "         'appeal': 169,\n",
       "         'those': 1744,\n",
       "         'presented': 146,\n",
       "         'delightfully': 14,\n",
       "         'artful': 11,\n",
       "         'gracefully': 9,\n",
       "         'slapstick': 62,\n",
       "         'way': 3023,\n",
       "         'ot': 859,\n",
       "         'best': 2281,\n",
       "         'comparison': 83,\n",
       "         'earlier': 260,\n",
       "         'probably': 1076,\n",
       "         'was': 19345,\n",
       "         'actual': 305,\n",
       "         'last': 1077,\n",
       "         'did': 2297,\n",
       "         'oach': 16,\n",
       "         'wanted': 530,\n",
       "         'mirror': 49,\n",
       "         'big': 1176,\n",
       "         'studios': 53,\n",
       "         'into': 3669,\n",
       "         'making': 1062,\n",
       "         'features': 253,\n",
       "         'exclusively': 19,\n",
       "         'also': 3093,\n",
       "         'hurry': 14,\n",
       "         'up': 4941,\n",
       "         'finish': 164,\n",
       "         'contractual': 3,\n",
       "         'obligation': 8,\n",
       "         'should': 1972,\n",
       "         'stayed': 69,\n",
       "         'together': 869,\n",
       "         'continued': 42,\n",
       "         'five': 298,\n",
       "         'more': 5613,\n",
       "         'years': 1761,\n",
       "         'hat': 2030,\n",
       "         'world': 1187,\n",
       "         'missed': 225,\n",
       "         'considering': 179,\n",
       "         'an': 9119,\n",
       "         'option': 28,\n",
       "         'atch': 203,\n",
       "         'enjoy': 685,\n",
       "         'great': 3286,\n",
       "         'performance': 1100,\n",
       "         'nemic': 1,\n",
       "         'comedydrama': 8,\n",
       "         'unhappy': 33,\n",
       "         'seemingly': 130,\n",
       "         'rushed': 58,\n",
       "         'affair': 131,\n",
       "         'featuring': 113,\n",
       "         'her': 7162,\n",
       "         'woebegone': 3,\n",
       "         'housewife': 26,\n",
       "         'who': 7945,\n",
       "         'slowly': 144,\n",
       "         'friends': 705,\n",
       "         'hitman': 43,\n",
       "         'whos': 298,\n",
       "         'been': 3682,\n",
       "         'hired': 89,\n",
       "         'kill': 431,\n",
       "         'husband': 372,\n",
       "         'hazz': 2,\n",
       "         'alminteri': 2,\n",
       "         'talkative': 8,\n",
       "         'gun': 179,\n",
       "         'adapted': 65,\n",
       "         'screenplay': 261,\n",
       "         'own': 1417,\n",
       "         'stagy': 6,\n",
       "         'setups': 12,\n",
       "         'backandforth': 1,\n",
       "         'dialogue': 586,\n",
       "         'quickly': 236,\n",
       "         'tires': 9,\n",
       "         'eye': 249,\n",
       "         'ear': 129,\n",
       "         'air': 251,\n",
       "         'gloom': 7,\n",
       "         'hangs': 38,\n",
       "         'over': 2190,\n",
       "         'entire': 579,\n",
       "         'project': 183,\n",
       "         'director': 1381,\n",
       "         'aul': 325,\n",
       "         'azursky': 4,\n",
       "         'cant': 1491,\n",
       "         'perpetual': 10,\n",
       "         'funk': 4,\n",
       "         'shes': 481,\n",
       "         'listless': 12,\n",
       "         'espite': 182,\n",
       "         'top': 551,\n",
       "         'talent': 355,\n",
       "         'including': 407,\n",
       "         'obert': 409,\n",
       "         'e': 3045,\n",
       "         'iro': 33,\n",
       "         'producers': 203,\n",
       "         'aithful': 5,\n",
       "         'fraudulent': 3,\n",
       "         'no': 4150,\n",
       "         'substance': 81,\n",
       "         'story': 4476,\n",
       "         'characters': 2821,\n",
       "         'rarely': 119,\n",
       "         'come': 1240,\n",
       "         'life': 2303,\n",
       "         'h': 459,\n",
       "         'ucio': 9,\n",
       "         'ulci': 20,\n",
       "         'peace': 54,\n",
       "         'infamous': 52,\n",
       "         'talian': 172,\n",
       "         'mostbr': 6,\n",
       "         'br': 23770,\n",
       "         'famous': 294,\n",
       "         'ombie': 74,\n",
       "         'absolutely': 532,\n",
       "         'unwatchable': 50,\n",
       "         'hebr': 7,\n",
       "         'sychic': 2,\n",
       "         'anhattan': 37,\n",
       "         'aby': 65,\n",
       "         'ell': 783,\n",
       "         'add': 279,\n",
       "         'unwatchablebr': 2,\n",
       "         'listbr': 10,\n",
       "         'plot': 2484,\n",
       "         'were': 4481,\n",
       "         'concerns': 67,\n",
       "         'nekkid': 4,\n",
       "         'woman': 967,\n",
       "         'wears': 64,\n",
       "         'goldbr': 3,\n",
       "         'mask': 73,\n",
       "         'string': 55,\n",
       "         'wants': 517,\n",
       "         'power': 303,\n",
       "         'young': 1334,\n",
       "         'dubbedbr': 2,\n",
       "         'stud': 8,\n",
       "         'magic': 157,\n",
       "         'arrows': 10,\n",
       "         'bow': 20,\n",
       "         'magicbr': 5,\n",
       "         'glow': 19,\n",
       "         'rrow': 4,\n",
       "         'boy': 507,\n",
       "         'teams': 30,\n",
       "         'guy': 1080,\n",
       "         'bad': 3415,\n",
       "         'wigbr': 3,\n",
       "         'spend': 221,\n",
       "         'movie': 16656,\n",
       "         'rescuing': 10,\n",
       "         'each': 960,\n",
       "         'flatbr': 4,\n",
       "         'action': 1173,\n",
       "         'sequences': 288,\n",
       "         'end': 2047,\n",
       "         'chick': 69,\n",
       "         'defeated': 25,\n",
       "         'notbr': 32,\n",
       "         'before': 1573,\n",
       "         'taking': 352,\n",
       "         'off': 2168,\n",
       "         'reminding': 15,\n",
       "         'me': 4020,\n",
       "         'why': 1586,\n",
       "         'broke': 65,\n",
       "         'withbr': 35,\n",
       "         'my': 4236,\n",
       "         'high': 661,\n",
       "         'school': 573,\n",
       "         'girlfriendbr': 5,\n",
       "         'bathes': 2,\n",
       "         'every': 1365,\n",
       "         'shot': 767,\n",
       "         'orange': 17,\n",
       "         'fills': 26,\n",
       "         'screen': 863,\n",
       "         'smoke': 41,\n",
       "         'othing': 150,\n",
       "         'like': 7463,\n",
       "         'smoky': 2,\n",
       "         'sequence': 358,\n",
       "         'make': 3123,\n",
       "         'youbr': 63,\n",
       "         'crave': 5,\n",
       "         'unny': 67,\n",
       "         'elight': 2,\n",
       "         'cigarette': 19,\n",
       "         'special': 818,\n",
       "         'effects': 892,\n",
       "         'arebr': 14,\n",
       "         'laughable': 151,\n",
       "         'our': 1038,\n",
       "         'ambiguously': 2,\n",
       "         'gay': 227,\n",
       "         'duo': 48,\n",
       "         'attacked': 60,\n",
       "         'dozens': 35,\n",
       "         'obviously': 420,\n",
       "         'pin': 17,\n",
       "         'scratches': 6,\n",
       "         'onbr': 63,\n",
       "         'itself': 624,\n",
       "         'majority': 91,\n",
       "         'budget': 563,\n",
       "         'must': 1231,\n",
       "         'beenbr': 11,\n",
       "         'spent': 211,\n",
       "         'on': 13515,\n",
       "         'ulcilicious': 1,\n",
       "         'gore': 332,\n",
       "         'which': 4713,\n",
       "         'consists': 59,\n",
       "         'entirely': 216,\n",
       "         'spurtingbr': 1,\n",
       "         'wounds': 24,\n",
       "         'ey': 107,\n",
       "         'use': 749,\n",
       "         'good': 5534,\n",
       "         'spurting': 4,\n",
       "         'wound': 35,\n",
       "         'abr': 12,\n",
       "         'while': 1560,\n",
       "         'when': 4770,\n",
       "         'you': 10498,\n",
       "         'overkill': 11,\n",
       "         'gets': 1316,\n",
       "         'boringbr': 25,\n",
       "         'kept': 317,\n",
       "         'having': 890,\n",
       "         'brightness': 5,\n",
       "         'setting': 238,\n",
       "         'anywaybr': 27,\n",
       "         'just': 6651,\n",
       "         'see': 4412,\n",
       "         'heck': 126,\n",
       "         'happeningbr': 9,\n",
       "         'here': 4010,\n",
       "         'lots': 292,\n",
       "         'talk': 308,\n",
       "         'fulfilling': 10,\n",
       "         'omens': 5,\n",
       "         'prophecies': 4,\n",
       "         'so': 7040,\n",
       "         'let': 556,\n",
       "         'mebr': 85,\n",
       "         'do': 3324,\n",
       "         'little': 2385,\n",
       "         'look': 1546,\n",
       "         'futureif': 1,\n",
       "         'find': 1596,\n",
       "         'watch': 2484,\n",
       "         'itbr': 391,\n",
       "         'will': 3545,\n",
       "         'regret': 82,\n",
       "         'scene': 2094,\n",
       "         'video': 576,\n",
       "         'box': 200,\n",
       "         'edia': 10,\n",
       "         'does': 2271,\n",
       "         'appear': 269,\n",
       "         'context': 111,\n",
       "         'whatsoever': 120,\n",
       "         'onquest': 1,\n",
       "         'conbr': 2,\n",
       "         'could': 3071,\n",
       "         'done': 1161,\n",
       "         'thisbr': 98,\n",
       "         'rated': 153,\n",
       "         'strong': 422,\n",
       "         'physical': 130,\n",
       "         'violence': 423,\n",
       "         'femalebr': 2,\n",
       "         'nudity': 201,\n",
       "         'brief': 159,\n",
       "         'male': 238,\n",
       "         'mild': 48,\n",
       "         'sexual': 263,\n",
       "         'contentbr': 3,\n",
       "         'aniel': 105,\n",
       "         'ay': 621,\n",
       "         'ewis': 72,\n",
       "         'actors': 1723,\n",
       "         'time': 4727,\n",
       "         'favorites': 79,\n",
       "         't': 5608,\n",
       "         'amazing': 449,\n",
       "         'how': 3201,\n",
       "         'throws': 67,\n",
       "         'himself': 842,\n",
       "         'plays': 847,\n",
       "         'realbr': 20,\n",
       "         'remember': 641,\n",
       "         'many': 2512,\n",
       "         'ago': 424,\n",
       "         'had': 4551,\n",
       "         'party': 168,\n",
       "         'house': 600,\n",
       "         'came': 676,\n",
       "         'sitting': 164,\n",
       "         'around': 1366,\n",
       "         'table': 53,\n",
       "         'eating': 84,\n",
       "         'drinking': 56,\n",
       "         'wine': 18,\n",
       "         'talking': 355,\n",
       "         'laughing': 198,\n",
       "         'there': 4125,\n",
       "         'pay': 200,\n",
       "         'attention': 352,\n",
       "         'hen': 1547,\n",
       "         'suddenly': 201,\n",
       "         'stopped': 88,\n",
       "         'glasses': 32,\n",
       "         'clink': 1,\n",
       "         'forks': 4,\n",
       "         'move': 256,\n",
       "         'food': 105,\n",
       "         'getting': 646,\n",
       "         'cold': 169,\n",
       "         'plates': 4,\n",
       "         'eyes': 441,\n",
       "         'crippled': 23,\n",
       "         'man': 1697,\n",
       "         'whose': 393,\n",
       "         'body': 361,\n",
       "         'against': 565,\n",
       "         'him': 3412,\n",
       "         'only': 4576,\n",
       "         'control': 201,\n",
       "         'left': 842,\n",
       "         'foot': 87,\n",
       "         'picked': 140,\n",
       "         'piece': 582,\n",
       "         'chalk': 5,\n",
       "         'seemed': 551,\n",
       "         'eternity': 23,\n",
       "         'tried': 331,\n",
       "         'write': 254,\n",
       "         'word': 332,\n",
       "         'floor': 107,\n",
       "         'finished': 130,\n",
       "         'writing': 484,\n",
       "         'knew': 369,\n",
       "         'witnessed': 40,\n",
       "         'three': 761,\n",
       "         'triumphs': 9,\n",
       "         'triumph': 46,\n",
       "         'human': 565,\n",
       "         'spirit': 170,\n",
       "         'cinema': 517,\n",
       "         'able': 538,\n",
       "         'capture': 114,\n",
       "         'moment': 427,\n",
       "         'actor': 827,\n",
       "         'act': 459,\n",
       "         'became': 288,\n",
       "         'characterbr': 36,\n",
       "         'im': 490,\n",
       "         'heridans': 4,\n",
       "         'y': 1164,\n",
       "         'eft': 40,\n",
       "         'oot': 23,\n",
       "         'riveting': 41,\n",
       "         'unsentimental': 4,\n",
       "         'biodrama': 1,\n",
       "         'about': 6907,\n",
       "         'hristy': 35,\n",
       "         'rown': 84,\n",
       "         'born': 116,\n",
       "         'cerebral': 16,\n",
       "         'palsy': 5,\n",
       "         'ublin': 12,\n",
       "         'slum': 7,\n",
       "         'artist': 110,\n",
       "         'writer': 296,\n",
       "         'found': 1022,\n",
       "         'love': 2292,\n",
       "         'lifebr': 58,\n",
       "         'ewiss': 7,\n",
       "         'performances': 682,\n",
       "         'mixed': 105,\n",
       "         'feelings': 157,\n",
       "         'believe': 979,\n",
       "         'greatest': 266,\n",
       "         'role': 1208,\n",
       "         'loved': 533,\n",
       "         'omewhere': 16,\n",
       "         'poster': 50,\n",
       "         'said': 889,\n",
       "         'families': 94,\n",
       "         'portrayed': 242,\n",
       "         'ought': 57,\n",
       "         'thought': 1370,\n",
       "         'everybody': 128,\n",
       "         'believable': 268,\n",
       "         'notch': 64,\n",
       "         'cast': 1422,\n",
       "         'music': 1118,\n",
       "         'soundtrack': 300,\n",
       "         'nice': 748,\n",
       "         'say': 2193,\n",
       "         'two': 2505,\n",
       "         'words': 352,\n",
       "         'recommend': 663,\n",
       "         'filmbr': 319,\n",
       "         'teve': 179,\n",
       "         'arellbr': 1,\n",
       "         'showed': 205,\n",
       "         'subtle': 172,\n",
       "         'depth': 183,\n",
       "         'touched': 67,\n",
       "         'truly': 648,\n",
       "         'commanding': 14,\n",
       "         'widower': 9,\n",
       "         'dedicated': 42,\n",
       "         'too': 2889,\n",
       "         'dad': 132,\n",
       "         'first': 3200,\n",
       "         'cost': 85,\n",
       "         'denying': 16,\n",
       "         'needsbr': 5,\n",
       "         'id': 212,\n",
       "         'petulant': 4,\n",
       "         'ass': 87,\n",
       "         'hy': 583,\n",
       "         'yes': 316,\n",
       "         'didbr': 19,\n",
       "         'nd': 2863,\n",
       "         'thats': 1086,\n",
       "         'perfect': 618,\n",
       "         'played': 1018,\n",
       "         'character': 2531,\n",
       "         'made': 3210,\n",
       "         'something': 1909,\n",
       "         'simply': 751,\n",
       "         'feeling': 447,\n",
       "         'conveyed': 29,\n",
       "         'perfectly': 250,\n",
       "         'deniedbr': 1,\n",
       "         'enied': 3,\n",
       "         'happinessbr': 5,\n",
       "         'fulfillmentbr': 2,\n",
       "         'lovebr': 19,\n",
       "         'osing': 6,\n",
       "         'your': 2146,\n",
       "         'painful': 162,\n",
       "         'beyond': 282,\n",
       "         'belief': 77,\n",
       "         'feel': 1152,\n",
       "         'againbr': 54,\n",
       "         'eautiful': 37,\n",
       "         'gave': 509,\n",
       "         'eight': 64,\n",
       "         'ten': 276,\n",
       "         'm': 1928,\n",
       "         'watching': 1712,\n",
       "         'now': 1319,\n",
       "         'pink': 16,\n",
       "         'erbia': 5,\n",
       "         'station': 97,\n",
       "         'crap': 358,\n",
       "         'hallow': 5,\n",
       "         'acting': 2473,\n",
       "         'sloppy': 48,\n",
       "         'seriesbr': 35,\n",
       "         'stupid': 623,\n",
       "         'attempt': 427,\n",
       "         'tudios': 32,\n",
       "         'money': 892,\n",
       "         'success': 238,\n",
       "         'ome': 683,\n",
       "         'times': 1250,\n",
       "         'idiotic': 55,\n",
       "         'lines': 608,\n",
       "         'speech': 66,\n",
       "         'actually': 1589,\n",
       "         'someone': 849,\n",
       "         'someones': 50,\n",
       "         'relative': 46,\n",
       "         'tudio': 16,\n",
       "         'ciibr': 1,\n",
       "         'bomb': 89,\n",
       "         'series': 1231,\n",
       "         'suck': 59,\n",
       "         'o': 2722,\n",
       "         'tamo': 2,\n",
       "         'peva': 2,\n",
       "         'comedy': 1162,\n",
       "         'elieve': 28,\n",
       "         'i': 1878,\n",
       "         'saw': 1233,\n",
       "         'lot': 1598,\n",
       "         'movies': 3063,\n",
       "         'comedies': 171,\n",
       "         'tell': 656,\n",
       "         'smile': 116,\n",
       "         'truth': 284,\n",
       "         'humour': 146,\n",
       "         'specialt': 1,\n",
       "         'caratherisic': 1,\n",
       "         'serbia': 1,\n",
       "         'former': 179,\n",
       "         'republic': 3,\n",
       "         'yugoslavia': 1,\n",
       "         'know': 2462,\n",
       "         'very': 5444,\n",
       "         'well': 3223,\n",
       "         'think': 2826,\n",
       "         'audience': 813,\n",
       "         'example': 519,\n",
       "         'uropecant': 1,\n",
       "         'ecause': 167,\n",
       "         'subtitles': 80,\n",
       "         'ruin': 86,\n",
       "         'hole': 51,\n",
       "         'thing': 1743,\n",
       "         'least': 1254,\n",
       "         'try': 740,\n",
       "         'ironic': 51,\n",
       "         'flick': 439,\n",
       "         'erbian': 11,\n",
       "         'history': 453,\n",
       "         'doesnt': 1857,\n",
       "         'understand': 707,\n",
       "         'f': 2683,\n",
       "         'got': 1431,\n",
       "         'chance': 363,\n",
       "         'blew': 42,\n",
       "         'part': 1525,\n",
       "         'longest': 20,\n",
       "         'reign': 14,\n",
       "         'ritish': 332,\n",
       "         'ueen': 80,\n",
       "         'ictoria': 111,\n",
       "         'holds': 102,\n",
       "         'distinctions': 4,\n",
       "         'apart': 209,\n",
       "         'current': 103,\n",
       "         'oldest': 35,\n",
       "         'ever': 2324,\n",
       "         'monarch': 8,\n",
       "         'living': 375,\n",
       "         'age': 520,\n",
       "         'she': 4144,\n",
       "         'youngest': 32,\n",
       "         'opposed': 56,\n",
       "         'nglish': 334,\n",
       "         'or': 7756,\n",
       "         'cottish': 48,\n",
       "         'coming': 411,\n",
       "         'throne': 15,\n",
       "         'girl': 907,\n",
       "         'eighteen': 6,\n",
       "         'yet': 916,\n",
       "         'whenever': 77,\n",
       "         'television': 324,\n",
       "         'programme': 7,\n",
       "         'seem': 840,\n",
       "         'interested': 239,\n",
       "         'older': 262,\n",
       "         'than': 4031,\n",
       "         'version': 803,\n",
       "         'modern': 326,\n",
       "         'audiences': 227,\n",
       "         'familiar': 208,\n",
       "         'udi': 13,\n",
       "         'ench': 13,\n",
       "         'rs': 108,\n",
       "         'oung': 166,\n",
       "         'tries': 533,\n",
       "         'redress': 2,\n",
       "         'balance': 65,\n",
       "         'showing': 304,\n",
       "         'events': 365,\n",
       "         'surrounding': 61,\n",
       "         'accession': 3,\n",
       "         'early': 629,\n",
       "         'rare': 184,\n",
       "         'distinction': 13,\n",
       "         'produced': 191,\n",
       "         'oyal': 18,\n",
       "         'arah': 76,\n",
       "         'uchess': 13,\n",
       "         'ork': 305,\n",
       "         'daughter': 363,\n",
       "         'rincess': 43,\n",
       "         'eatrice': 14,\n",
       "         'appearance': 163,\n",
       "         'extrabr': 1,\n",
       "         'main': 911,\n",
       "         'strands': 10,\n",
       "         'intrigues': 7,\n",
       "         'ictorias': 26,\n",
       "         'mother': 452,\n",
       "         'ent': 68,\n",
       "         'highly': 388,\n",
       "         'unpopular': 10,\n",
       "         'figure': 274,\n",
       "         'even': 4402,\n",
       "         'largely': 91,\n",
       "         'influence': 76,\n",
       "         'adviser': 10,\n",
       "         'ir': 104,\n",
       "         'ohn': 840,\n",
       "         'onroy': 14,\n",
       "         'widely': 32,\n",
       "         'rumoured': 4,\n",
       "         'lover': 180,\n",
       "         'ccording': 52,\n",
       "         'unfounded': 1,\n",
       "         'rumour': 5,\n",
       "         'late': 417,\n",
       "         'uke': 142,\n",
       "         'natural': 152,\n",
       "         'father': 712,\n",
       "         'second': 666,\n",
       "         'strand': 7,\n",
       "         'growing': 103,\n",
       "         'romance': 263,\n",
       "         'between': 1375,\n",
       "         'erman': 194,\n",
       "         'cousin': 48,\n",
       "         'rince': 100,\n",
       "         'lbert': 103,\n",
       "         'ing': 373,\n",
       "         'eopold': 16,\n",
       "         'elgium': 13,\n",
       "         'uncle': 80,\n",
       "         'both': 1179,\n",
       "         'eopolds': 1,\n",
       "         'hope': 500,\n",
       "         'increase': 17,\n",
       "         'prestige': 9,\n",
       "         'ouse': 210,\n",
       "         'axeoburg': 1,\n",
       "         'belonged': 14,\n",
       "         'third': 235,\n",
       "         'strangest': 14,\n",
       "         'episodes': 379,\n",
       "         'political': 247,\n",
       "         'edchamber': 6,\n",
       "         'risis': 10,\n",
       "         'supporters': 17,\n",
       "         'ory': 21,\n",
       "         'arty': 73,\n",
       "         'traditionally': 11,\n",
       "         'supported': 29,\n",
       "         'monarchy': 3,\n",
       "         'rioted': 1,\n",
       "         'perceived': 14,\n",
       "         'favour': 22,\n",
       "         'hig': 3,\n",
       "         'leader': 94,\n",
       "         'ord': 207,\n",
       "         'elbourne': 22,\n",
       "         'though': 1609,\n",
       "         'higs': 1,\n",
       "         'historically': 31,\n",
       "         'quasirepublican': 1,\n",
       "         'system': 140,\n",
       "         'government': 141,\n",
       "         'reduced': 45,\n",
       "         'figureheadbr': 2,\n",
       "         'criptwriter': 1,\n",
       "         'ulian': 22,\n",
       "         'ellowes': 8,\n",
       "         'known': 369,\n",
       "         'onservative': 4,\n",
       "         'views': 76,\n",
       "         'wondered': 60,\n",
       "         'if': 4563,\n",
       "         'coloured': 5,\n",
       "         'treatment': 94,\n",
       "         'themes': 165,\n",
       "         'seems': 1434,\n",
       "         'lean': 20,\n",
       "         'side': 521,\n",
       "         'ories': 2,\n",
       "         'predecessors': 16,\n",
       "         'heir': 133,\n",
       "         'eel': 27,\n",
       "         'shown': 395,\n",
       "         'statesmanlike': 1,\n",
       "         'dignified': 15,\n",
       "         'whereas': 46,\n",
       "         'dash': 14,\n",
       "         'charm': 162,\n",
       "         'devious': 14,\n",
       "         'uninterested': 6,\n",
       "         'social': 200,\n",
       "         'reform': 9,\n",
       "         'these': 1955,\n",
       "         'characterisations': 7,\n",
       "         'glosses': 3,\n",
       "         'fact': 1383,\n",
       "         'few': 1639,\n",
       "         'eform': 1,\n",
       "         'ct': 22,\n",
       "         'ended': 207,\n",
       "         'corrupt': 48,\n",
       "         'electoral': 1,\n",
       "         'rotten': 35,\n",
       "         'boroughs': 3,\n",
       "         'benefited': 6,\n",
       "         'illiam': 241,\n",
       "         's': 3636,\n",
       "         'unconstitutional': 1,\n",
       "         'dismissal': 3,\n",
       "         'administrationbr': 2,\n",
       "         'essons': 6,\n",
       "         'dynastic': 2,\n",
       "         'constitutional': 4,\n",
       "         'transfer': 36,\n",
       "         'contains': 150,\n",
       "         'share': 157,\n",
       "         'inaccuracies': 24,\n",
       "         'injured': 25,\n",
       "         'dward': 79,\n",
       "         'xfords': 1,\n",
       "         'fifties': 23,\n",
       "         'youthful': 20,\n",
       "         'ettany': 8,\n",
       "         'disliked': 34,\n",
       "         'sisterinlaw': 3,\n",
       "         'doubt': 284,\n",
       "         'gone': 249,\n",
       "         'bawl': 1,\n",
       "         'abuse': 72,\n",
       "         'during': 817,\n",
       "         'state': 185,\n",
       "         'banquet': 6,\n",
       "         'doing': 631,\n",
       "         'failed': 202,\n",
       "         'significance': 31,\n",
       "         'force': 150,\n",
       "         'sign': 107,\n",
       "         'egency': 5,\n",
       "         'rder': 36,\n",
       "         'uchesss': 2,\n",
       "         'position': 65,\n",
       "         'clear': 283,\n",
       "         'provided': 79,\n",
       "         'become': 644,\n",
       "         'egent': 3,\n",
       "         'still': 2021,\n",
       "         'under': 453,\n",
       "         'paper': 67,\n",
       "         'signed': 33,\n",
       "         'altered': 21,\n",
       "         'provisions': 1,\n",
       "         'ctbr': 1,\n",
       "         'occasional': 84,\n",
       "         'infelicities': 1,\n",
       "         'playing': 640,\n",
       "         'chess': 39,\n",
       "         'comparing': 34,\n",
       "         'themselves': 476,\n",
       "         'pawns': 5,\n",
       "         'moved': 131,\n",
       "         'chessboard': 2,\n",
       "         'metaphor': 29,\n",
       "         'hackneyed': 36,\n",
       "         'whole': 1126,\n",
       "         'complete': 392,\n",
       "         'anger': 95,\n",
       "         'ajor': 21,\n",
       "         'clich': 133,\n",
       "         'ahead': 126,\n",
       "         'warning': 91,\n",
       "         'et': 506,\n",
       "         'spite': 53,\n",
       "         'scenes': 1925,\n",
       "         'especially': 856,\n",
       "         'iranda': 22,\n",
       "         'ichardson': 36,\n",
       "         'scheming': 20,\n",
       "         'ark': 321,\n",
       "         'trong': 29,\n",
       "         'obnoxious': 67,\n",
       "         'visually': 91,\n",
       "         'attractive': 131,\n",
       "         'sumptuous': 9,\n",
       "         'style': 588,\n",
       "         'associate': 16,\n",
       "         'historical': 157,\n",
       "         'drama': 505,\n",
       "         'roadbent': 7,\n",
       "         'gives': 634,\n",
       "         'amusing': 183,\n",
       "         'turn': 547,\n",
       "         'although': 599,\n",
       "         'occasionally': 100,\n",
       "         'succumb': 6,\n",
       "         'temptation': 11,\n",
       "         'going': 1563,\n",
       "         'lthough': 394,\n",
       "         'disastrously': 2,\n",
       "         'oulin': 7,\n",
       "         'ougebr': 2,\n",
       "         'reason': 905,\n",
       "         'films': 3113,\n",
       "         'however': 584,\n",
       "         'mily': 46,\n",
       "         'lunt': 31,\n",
       "         'upert': 15,\n",
       "         'riend': 19,\n",
       "         'lovers': 126,\n",
       "         'real': 1755,\n",
       "         'delightful': 91,\n",
       "         'portrayal': 191,\n",
       "         'longer': 181,\n",
       "         'old': 1620,\n",
       "         'lady': 185,\n",
       "         'popular': 221,\n",
       "         'imagination': 141,\n",
       "         'blackclad': 2,\n",
       "         'idow': 2,\n",
       "         'indsor': 4,\n",
       "         'perpetually': 13,\n",
       "         'amused': 35,\n",
       "         'determined': 58,\n",
       "         'strongminded': 1,\n",
       "         'loving': 107,\n",
       "         'er': 341,\n",
       "         'happy': 345,\n",
       "         'family': 1199,\n",
       "         'reasons': 241,\n",
       "         'succeeded': 38,\n",
       "         'reestablishing': 3,\n",
       "         'affections': 14,\n",
       "         'people': 3393,\n",
       "         'ith': 475,\n",
       "         'exception': 151,\n",
       "         'eorge': 299,\n",
       "         'anoverian': 1,\n",
       "         'ancestors': 12,\n",
       "         'notoriously': 10,\n",
       "         'lacking': 80,\n",
       "         'matrimonial': 2,\n",
       "         'virtues': 11,\n",
       "         'touching': 147,\n",
       "         'gripping': 63,\n",
       "         'exploration': 30,\n",
       "         'key': 135,\n",
       "         'period': 287,\n",
       "         'tlantis': 67,\n",
       "         'probally': 1,\n",
       "         'isney': 285,\n",
       "         'seen': 2517,\n",
       "         'intelligent': 223,\n",
       "         'weel': 1,\n",
       "         'written': 561,\n",
       "         'script': 1117,\n",
       "         'brings': 244,\n",
       "         'back': 1816,\n",
       "         'lassics': 8,\n",
       "         'such': 1985,\n",
       "         'ion': 65,\n",
       "         ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 25000   # let's make a model that only understand 25000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'the', 'a', 'and', 'of'] ... ['onchata', 'comparative', 'onceiving', 'onceinalifetime', 'omo']\n"
     ]
    }
   ],
   "source": [
    "words, count = np.unique(all_words, return_counts=True)\n",
    "idxs = np.argsort(count)[-n_words:]\n",
    "vocab = ['<UNK>'] + list(words[idxs][::-1])\n",
    "print(vocab[:5], '...', vocab[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very surprisingly, the most commonly used word is _the_. The 25000th most used word is _chimneys_. We have added a special word `<UNK>` which we will used to mark words outside our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now turn a sentence into a sequence of integers that correspond to the position in the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_d = {vocab[i]: i for i in range(len(vocab))}  # for quick look-up\n",
    "def sentence_to_integer_sequence(s):\n",
    "    return torch.tensor([vocab_d[x] if x in vocab_d else 0 for x in s.split()], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([147,  62, 443,   1,  18,   0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_integer_sequence(\"i really liked the movie xenopus51\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now representing words in a \"25000\"-dimensional space: we have a unique integer for each word we can represent. To reduce this complexity, we instead intend to represent each word as a 50-dimensional real vector. Pytorch to the rescue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocab), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Embedding` assigns are random, trainable vector to each word. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2968,  1.0202,  0.0757, -0.3996, -0.6972, -0.1607,  1.3119, -1.8031,\n",
      "          1.6506, -2.2972,  0.5593, -1.1413, -0.9477,  0.4262,  1.4848,  1.5991,\n",
      "         -0.2156, -0.4719,  1.0799,  2.1833, -0.3499, -0.4861, -0.4047, -2.8566,\n",
      "          1.3584,  0.7612,  0.5755, -0.6354,  1.2501, -0.0080,  0.4063,  1.3415,\n",
      "          0.9766,  0.4744,  2.0880, -0.5770, -0.0662,  0.2420, -0.3170,  0.5590,\n",
      "          0.2885,  0.1820, -0.1330, -0.0611,  1.7603,  1.9476,  0.8143,  0.4350,\n",
      "          0.3666,  1.4955]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding(sentence_to_integer_sequence(\"movie\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special `<UNK>` word, which signifies unknown we can choose to zero out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.weight.data[0, :] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how we represent a sentence then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50])\n",
      "tensor([[ 5.1276e-02,  6.7472e-01,  2.2765e-01, -5.6824e-01, -2.7173e+00,\n",
      "          1.9144e+00,  1.6569e-01,  1.1173e+00, -4.9625e-01,  1.0714e+00,\n",
      "          4.4696e-01, -5.3708e-01, -1.2415e+00, -5.1944e-02, -8.7727e-01,\n",
      "          3.1294e-01,  1.5166e+00, -7.9451e-01, -7.4870e-01, -3.9630e-01,\n",
      "          5.0324e-01, -4.5160e-01, -6.0607e-01, -7.7758e-01, -1.1998e+00,\n",
      "          9.9511e-01, -1.5146e+00, -3.0451e-01,  2.7203e+00, -2.2697e+00,\n",
      "         -6.1929e-02, -2.1723e-01,  1.4525e+00,  8.1341e-01,  4.1871e-02,\n",
      "          6.2729e-01, -8.6162e-01, -7.1337e-02,  7.6250e-01, -2.3121e+00,\n",
      "          2.0560e+00, -8.0771e-01,  6.5941e-01, -3.5106e-01, -7.1696e-02,\n",
      "         -1.8593e+00,  1.4441e+00, -2.5056e+00, -9.8652e-01,  5.7731e-01],\n",
      "        [ 2.7958e-01, -8.8597e-02,  1.4613e+00,  1.8589e-01, -1.7020e-01,\n",
      "         -2.8023e-01,  2.9275e-01,  4.4134e-01, -5.3426e-02, -2.1714e+00,\n",
      "          1.7586e+00,  1.7863e+00, -8.9244e-01, -4.0376e-01, -1.0448e+00,\n",
      "         -2.7645e-01, -1.2233e+00, -1.3474e-01, -5.5665e-01, -2.8133e-01,\n",
      "         -1.9523e-01, -1.0362e+00, -6.6019e-01,  7.9338e-01,  1.1264e+00,\n",
      "          1.2382e-01,  1.2879e+00,  1.7004e+00, -5.6602e-01,  6.6641e-01,\n",
      "          2.3804e-02, -3.6577e-01,  3.1733e-01,  1.1679e-01, -1.5928e+00,\n",
      "         -8.2187e-01, -5.2930e-01, -5.6666e-01,  7.4420e-01, -4.3852e-01,\n",
      "         -5.1637e-01,  8.0492e-01, -2.3599e-01, -2.0659e-01,  4.0059e-01,\n",
      "         -1.2443e+00,  3.2935e-03, -2.7647e-01, -7.7243e-01, -6.5157e-01],\n",
      "        [ 8.1003e-04, -1.6584e+00, -5.7874e-01,  1.6096e+00,  1.2295e+00,\n",
      "          9.4025e-01,  1.5092e+00,  8.9925e-01,  1.1839e+00, -1.0796e+00,\n",
      "          1.6471e+00,  1.8124e-01,  6.0288e-01,  1.3968e+00, -6.5599e-01,\n",
      "          2.4993e-01, -2.8772e-01, -8.6904e-01,  1.8819e+00,  1.1689e+00,\n",
      "         -3.6870e-01,  5.4844e-01, -8.8926e-01,  5.0697e-01,  5.8603e-01,\n",
      "          2.0984e-01,  7.9277e-01, -1.5694e+00, -3.7815e-01, -6.6374e-01,\n",
      "          8.5303e-01, -1.8100e+00,  6.6931e-01,  1.2170e-01,  7.5955e-01,\n",
      "          2.5577e+00,  1.1855e+00, -1.5285e+00,  3.5537e-01,  4.2702e-02,\n",
      "         -2.2312e+00, -5.1755e-02,  4.4310e-01, -5.3032e-01, -1.5621e+00,\n",
      "          1.4826e+00,  1.9627e-01, -6.1152e-01, -1.5545e+00,  6.0238e-01],\n",
      "        [-1.7149e+00,  2.3462e-01,  5.6945e-01,  2.1983e-02,  3.8429e-01,\n",
      "         -4.4302e-01, -4.5605e-01, -9.8278e-02,  3.4888e-01,  4.7863e-01,\n",
      "         -2.3239e-01,  4.6823e-01, -2.8418e-01, -1.0101e+00, -2.0665e-01,\n",
      "         -1.3400e+00, -6.9816e-01, -1.6850e+00,  1.3179e+00,  5.3027e-01,\n",
      "         -5.3116e-01,  1.8179e-01,  4.7139e-01, -4.2675e-01,  1.1062e+00,\n",
      "         -1.6923e+00,  7.2204e-01,  8.5784e-01,  1.3943e+00,  8.5323e-01,\n",
      "         -2.9382e-01, -1.1274e+00,  1.8104e+00,  5.1387e-01, -1.2367e+00,\n",
      "          2.8926e-01,  3.7361e-01, -2.9942e-01,  3.9823e-01, -2.9040e-01,\n",
      "          5.5168e-01, -3.7959e-01,  6.6876e-01,  1.3321e+00,  1.0795e+00,\n",
      "          6.7789e-01,  1.3624e-01,  2.1791e-01, -3.0330e-02, -6.1532e-01],\n",
      "        [-1.2968e+00,  1.0202e+00,  7.5724e-02, -3.9962e-01, -6.9722e-01,\n",
      "         -1.6073e-01,  1.3119e+00, -1.8031e+00,  1.6506e+00, -2.2972e+00,\n",
      "          5.5931e-01, -1.1413e+00, -9.4772e-01,  4.2620e-01,  1.4848e+00,\n",
      "          1.5991e+00, -2.1562e-01, -4.7186e-01,  1.0799e+00,  2.1833e+00,\n",
      "         -3.4991e-01, -4.8611e-01, -4.0469e-01, -2.8566e+00,  1.3584e+00,\n",
      "          7.6125e-01,  5.7552e-01, -6.3540e-01,  1.2501e+00, -8.0096e-03,\n",
      "          4.0630e-01,  1.3415e+00,  9.7655e-01,  4.7436e-01,  2.0880e+00,\n",
      "         -5.7701e-01, -6.6196e-02,  2.4201e-01, -3.1703e-01,  5.5902e-01,\n",
      "          2.8855e-01,  1.8204e-01, -1.3305e-01, -6.1086e-02,  1.7603e+00,\n",
      "          1.9476e+00,  8.1435e-01,  4.3504e-01,  3.6662e-01,  1.4955e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding(sentence_to_integer_sequence(\"i really liked the movie xenopus51\")).shape)\n",
    "print(embedding(sentence_to_integer_sequence(\"i really liked the movie xenopus51\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the sentence bascially becomes a 6x50 pixel image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use `nn.LSTM` after an embedding to define a neural network for sentenes.\n",
    "\n",
    "This network will have a _lot_ of parameters. For each word, 50 parameters needs to be trained, and then comes the LSTM on top of that.\n",
    "This is the reason that _transfer learning_ is so important in natural language processing (NLP).\n",
    "\n",
    "Perhaps the simplest form of transfer learning is to use a pretrained embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.6B.50d.pkl', 'rb') as f:\n",
    "    glove = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30824 ,  0.17223 , -0.23339 ,  0.023105,  0.28522 ,  0.23076 ,\n",
       "       -0.41048 , -1.0035  , -0.2072  ,  1.4327  , -0.80684 ,  0.68954 ,\n",
       "       -0.43648 ,  1.1069  ,  1.6107  , -0.31966 ,  0.47744 ,  0.79395 ,\n",
       "       -0.84374 ,  0.064509,  0.90251 ,  0.78609 ,  0.29699 ,  0.76057 ,\n",
       "        0.433   , -1.5032  , -1.6423  ,  0.30256 ,  0.30771 , -0.87057 ,\n",
       "        2.4782  , -0.025852,  0.5013  , -0.38593 , -0.15633 ,  0.45522 ,\n",
       "        0.04901 , -0.42599 , -0.86402 , -1.3076  , -0.29576 ,  1.209   ,\n",
       "       -0.3127  , -0.72462 , -0.80801 ,  0.082667,  0.26738 , -0.98177 ,\n",
       "       -0.32147 ,  0.99823 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These pretrained word embeddings will have a good structure to them. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance b/w queen and prince = 3.3926491063677284\n",
      "Distance b/w movie and prince = 6.450784821820618\n"
     ]
    }
   ],
   "source": [
    "print('Distance b/w queen and prince =', np.linalg.norm(glove['queen'] - glove['prince']))\n",
    "print('Distance b/w movie and prince =', np.linalg.norm(glove['movie'] - glove['prince']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even sometimes get away with doing algebra with these vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "queenlike = glove['king'] - glove['man'] + glove['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance b/w queen and algebraic queen = 2.8391206432941996\n",
      "Distance b/w queen and king = 3.4777562289742345\n"
     ]
    }
   ],
   "source": [
    "print('Distance b/w queen and algebraic queen =', np.linalg.norm(glove['queen'] - queenlike))\n",
    "print('Distance b/w queen and king =', np.linalg.norm(glove['queen'] - glove['king']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill out our embedding layer using these pretrained vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the words in the vocab, 73.376 % were updated using Glove vectors\n",
      "Examples of words not found : ['owever', 'ichael', 'itbr', 'nfortunately', 'nglish', 'ritish']\n"
     ]
    }
   ],
   "source": [
    "filled = 0\n",
    "not_found = []\n",
    "for i, w in enumerate(vocab):\n",
    "    if w in glove:\n",
    "        embedding.weight.data[i, :] = torch.tensor(glove[w], dtype=torch.float)\n",
    "        filled += 1\n",
    "    else:\n",
    "        not_found.append(w)\n",
    "print(f'Of the words in the vocab, {100 * filled / (len(vocab) - 1)} % were updated using Glove vectors')\n",
    "print('Examples of words not found :', not_found[1:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the words we do not find are due to misspellings. You now have three choices before you continue with the exercise:\n",
    "\n",
    "(1) Use _hunspell_ or similar to fix misspelled words\n",
    "\n",
    "(2) Change the vocabulary (`vocab`) to be based on words that are both frequent in the text and have glove vectors\n",
    "\n",
    "(3) Ignore the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with Glove vectors we do not need to train the embedding. We can consider it fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(25001, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a neural network using `nn.LSTM` layers to classify the IMDB reviews.\n",
    "\n",
    "Ideas:\n",
    "\n",
    " - The sentences can be quite long, so you might want to limit them to, say, maximum 100 words\n",
    " - `nn.LSTM` can take batched input, but be careful with `batch_first=True/False`.\n",
    " - If batched input are used, they normally have to be equal in size. You can put sentences to always be 100 words long, by adding `<UNK>` words to short sentences.\n",
    " - Alternatively, `nn.LSTM` can also accept batched, variable-length input using `torch.nn.utils.rnn.pack_sequence`.\n",
    " - (a finaly, albeit slow, alternative is to simple run the LSTM on un-batched input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'he', 'that']\n",
      "['chessboard', 'chested', 'overstates', 'migraine', 'chow', 'minuets', 'righthand', 'migraines', 'charted', 'mechanisms']\n"
     ]
    }
   ],
   "source": [
    "words, count = np.unique(all_words, return_counts=True)\n",
    "words = words[np.argsort(count)[::-1]]\n",
    "vocab = ['<UNK>']\n",
    "for w in words:\n",
    "    if w in glove:\n",
    "        vocab.append(w)    \n",
    "    if len(vocab) == n_words:\n",
    "        break\n",
    "\n",
    "print(vocab[:10])\n",
    "print(vocab[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocab), 50)\n",
    "embedding.requires_grad_(False)\n",
    "for i, w in enumerate(vocab):\n",
    "    if w in glove:\n",
    "        embedding.weight[i, :] = torch.tensor(glove[w], dtype=embedding.weight.dtype)\n",
    "embedding.weight[0, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_d = {vocab[i]: i for i in range(len(vocab))}  # for quick look-up\n",
    "max_seq_len = 100\n",
    "\n",
    "def sentence_to_integer_sequence(s):\n",
    "    return torch.tensor([vocab_d[x] if x in vocab_d else 0 for x in s.split()][:max_seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "train_seq = [sentence_to_integer_sequence(x) for x in train_text]\n",
    "test_seq = [sentence_to_integer_sequence(x) for x in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMDBNet(\n",
       "  (lstm): LSTM(50, 30, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=60, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IMDBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(50, 30, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(2 * 30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        final_hidden = output[:, -1, :]\n",
    "        return self.sigmoid(self.linear(final_hidden)[:, 0])\n",
    "    \n",
    "net = IMDBNet()\n",
    "embedding.to(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "train = pad_sequence(train_seq, batch_first=True)\n",
    "test = pad_sequence(test_seq, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(list(zip(train, train_labels)), batch_size=128)\n",
    "test_loader = DataLoader(list(zip(test, test_labels)), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.28it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 0.005389249348640442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.35it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss = 0.00536091159582138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss = 0.005470919674634933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.31it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss = 0.005358284306526184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.32it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss = 0.005359417927265167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.24it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss = 0.005450261968374252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.26it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss = 0.005420373630523682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.26it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss = 0.0053317811846733095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.27it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss = 0.005136041814088822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.10it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss = 0.005524197727441788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss = 0.005439566004276275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.07it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss = 0.005424370574951172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.06it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss = 0.005392865210771561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.07it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss = 0.005347777825593948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.04it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss = 0.005252210301160813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.03it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss = 0.005129795449972153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.02it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss = 0.004891270017623901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.12it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss = 0.0045809281706809995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.04it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss = 0.004361371365189552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.03it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss = 0.0042273925215005875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.16it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 loss = 0.004133732342720031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.03it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 loss = 0.0039800951093435285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:16<00:00,  4.89it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 loss = 0.0038960348933935163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 loss = 0.0038344419807195664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.08it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 loss = 0.003780973729491234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  4.96it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 loss = 0.003724361830949783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.06it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 loss = 0.0036750845313072203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.17it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 loss = 0.00363691782951355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss = 0.0035966800928115845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.22it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 loss = 0.00357138038277626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  4.98it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 loss = 0.003564124596118927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:17<00:00,  4.61it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 loss = 0.0035082209646701812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  4.99it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 loss = 0.0034760828703641893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.04it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 loss = 0.0034585849821567537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.17it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 loss = 0.0034003431648015974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.09it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 loss = 0.00334203542470932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.09it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 loss = 0.0033410898715257645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 loss = 0.0033122685760259628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.16it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 loss = 0.003295270308852196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  4.98it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 loss = 0.003252117520570755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 loss = 0.0031981156349182127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.15it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 loss = 0.003125904953479767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.39it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 loss = 0.003089902475476265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.18it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 loss = 0.003055961447954178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:16<00:00,  4.66it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 loss = 0.0029714376404881477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.16it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 loss = 0.002908417809009552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 loss = 0.0028618209347128867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.17it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 loss = 0.002860668797045946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.25it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 loss = 0.0027574351474642755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.19it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 loss = 0.0027101651564240456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.30it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:13,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 loss = 0.0027009857654571533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:17<00:00,  4.56it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 loss = 0.0026113946571946142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.02it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 loss = 0.0025645316798239945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.21it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 loss = 0.002578785737603903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.22it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 loss = 0.0024693561844527723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.12it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 loss = 0.002431293272972107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.29it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 loss = 0.002613813494890928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.10it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 loss = 0.002466647853702307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.22it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 loss = 0.0024741932429373265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.29it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 loss = 0.002401602405309677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.03it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 loss = 0.002351766015961766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.29it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 loss = 0.0022194566927850245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 loss = 0.0021562471702694895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.27it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 loss = 0.0020958400301635265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.25it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 loss = 0.002021418996155262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 loss = 0.0020134456373751162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 loss = 0.0018933440232649446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.42it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 loss = 0.00184073895085603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.35it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 loss = 0.0017879243981093168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.07it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 loss = 0.0018194562505930662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.17it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 loss = 0.001822534103691578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.26it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 loss = 0.0017764240853488445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.21it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 loss = 0.0018119452185928822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.16it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 loss = 0.001985166067443788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.17it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 loss = 0.001808354996331036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.10it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 loss = 0.0017587558280676603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.11it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 loss = 0.0015813358705490828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 loss = 0.0015697043407708407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.22it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 loss = 0.0016087977522984147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.19it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss = 0.0015434708714485168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.15it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 loss = 0.0014455534882843494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.41it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 loss = 0.0013976826804690064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.41it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 loss = 0.0014329652297310532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.42it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 loss = 0.0016088279194198549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.42it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 loss = 0.001416977541334927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.41it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 loss = 0.0016288387274369597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.03it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 loss = 0.001679326254595071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.19it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 loss = 0.0012500101488083601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.20it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 loss = 0.0011477841725572944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.39it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 loss = 0.0011430880770552903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.36it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 loss = 0.0011508140650577843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.36it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 loss = 0.0011033616974018515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:14<00:00,  5.36it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 loss = 0.0010050127591006458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.19it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 loss = 0.001077073425007984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.13it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 loss = 0.001139446108788252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.19it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 loss = 0.0011172955614514649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.18it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:14,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 loss = 0.0010727595877833664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.11it/s]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 loss = 0.0010368263479787856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  5.14it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:15,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 loss = 0.001125620032986626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:15<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 loss = 0.001214676957949996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "loss_criterion = nn.BCELoss()\n",
    "net.to(device)\n",
    "for epoch in range(100):\n",
    "    acc_loss = 0.0\n",
    "    for seq, label in tqdm(train_loader):\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        output = net(seq)\n",
    "        loss = loss_criterion(output, label)\n",
    "        loss.backward()  # calculate gradients: d Loss / d Paramters\n",
    "        opt.step()  # take a step down-hill\n",
    "        opt.zero_grad()  # zero the gradient calculations for next iteration\n",
    "        acc_loss += float(loss)\n",
    "    acc_loss /= len(train)\n",
    "    print(f'Epoch {epoch + 1} loss = {acc_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:08<00:00,  9.14it/s]\n",
      "  1%|▏         | 1/79 [00:00<00:08,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = tensor(0.9623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:08<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = tensor(0.7646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "count = 0\n",
    "for seq, label in tqdm(train_loader):\n",
    "    seq = seq.to(device)\n",
    "    label = label.to(device)\n",
    "    output = net(seq)\n",
    "    acc += torch.sum(torch.eq(torch.round(output), label))\n",
    "    count += len(label)\n",
    "acc = acc / count\n",
    "print('Train accuracy =', acc)\n",
    "\n",
    "acc = 0\n",
    "count = 0\n",
    "for seq, label in tqdm(test_loader):\n",
    "    seq = seq.to(device)\n",
    "    label = label.to(device)\n",
    "    output = net(seq)\n",
    "    acc += torch.sum(torch.eq(torch.round(output), label))\n",
    "    count += len(label)\n",
    "acc = acc / count\n",
    "print('Test accuracy =', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMDBNet(\n",
       "  (lstm): LSTM(50, 30, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=60, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.cpu()\n",
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819666147232056"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"fargo is a great comedy\")[None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22874943912029266"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"worst movie i have ever seen\")[None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959909081459045"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"best movie i have ever seen\")[None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540596604347229"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"i don't really know how i feel about this movie\")[None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82257479429245"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"at first i thought this would be terrible, but then it turned out to be really nice\")[None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20609375834465027"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(net(sentence_to_integer_sequence(\"at first i thought this would be good, but then it turned out to be really terrible\")[None, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in NLP, a lot of unlabelled text is available. We can use this to pretrain the model, before fine-tuning to the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "with open('unlabelled.json') as f:\n",
    "    text = json.load(f)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to pretrain is to train a _language model_. This is model that tries to predict the next word in a sentence. For instance, given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is still a pretty bad and silly simplistic typical slasher but when being compared to the previous sequel \"Slumber Party Massacre II\" this movie is a step'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(text[2].split()[:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can you guess the next word?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a language model, we consider the above the input, and the out is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'up'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[2].split()[28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input we encode using the embedding, while the output is a probability map over words.\n",
    "In other words, the last layer is something like `nn.Linear(..., len(vocab))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a language model.\n",
    "\n",
    "After you have trained the model, try to make to complete sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "### Exercise 3 (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the last layer of the now trained language model and use it to train on the original IMDB-problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
