{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs and Ice core data\n",
    "\n",
    "In this exercise we are going to be classifying ashes found in ice core drilling. We will be dealing with a dataset (provided by Niccolo Maffezzoli, a former TA in 'Applied Statistics') that labels images and meta-data into two types of volcanic ashes: _Grimsvotn_ og _Campanian_.\n",
    "\n",
    "The data for this exercise consists of both scalar values (.csv files) and images (in directories), already split into training and testing samples, and can be found here:\n",
    "https://sid.erda.dk/share_redirect/gqwa15no19\n",
    "\n",
    "Your task will be to make the best classifier. First you will make a classifier based on the image data alone, then one based on the meta data alone, and finally one that combines both. You are free to use whatever methods you wish, but ideas will be provided... :)\n",
    "\n",
    "NOTE: The data should be placed *in the same directory as the code* in order for the code to run out of the box.\n",
    "\n",
    "***\n",
    "\n",
    "Author: Niccolo Maffezzoli, Amalie Mygind, and Troels Petersen\n",
    "\n",
    "Email: petersen@nbi.dk\n",
    "\n",
    "Date: 13th of May 2023 (latest version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('supervised_train.csv')\n",
    "train, val = train_test_split(train_df, test_size=0.3, random_state=42)\n",
    "test = pd.read_csv('supervised_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using PyTorch's DataLoader to make batches of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mva = ['Area (ABD)', 'Area (Filled)', 'Aspect Ratio', 'Biovolume (Cylinder)',\n",
    "       'Biovolume (P. Spheroid)', 'Circle Fit',\n",
    "       'Circularity', 'Circularity (Hu)', 'Compactness', 'Convex Perimeter',\n",
    "       'Convexity', 'Diameter (ABD)', 'Diameter (ESD)', 'Edge Gradient',\n",
    "       'Elongation', 'Feret Angle Max', 'Feret Angle Min', 'Fiber Curl',\n",
    "       'Fiber Straightness', 'Geodesic Aspect Ratio', 'Geodesic Length',\n",
    "       'Geodesic Thickness', 'Intensity', 'Length', 'Particles Per Chain',\n",
    "       'Perimeter', 'Roughness', 'Sigma Intensity', 'Sum Intensity',\n",
    "       'Symmetry', 'Transparency', 'Volume (ABD)', 'Volume (ESD)', 'Width']\n",
    "\n",
    "class ParticleDataset():\n",
    "    # This class is simply a \"list-like\" object\n",
    "    # that will load an image on the fly (using Image.open).\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.imgpaths = df['imgpaths'].to_numpy()\n",
    "        # self.imgpaths = df[path+'train/'].to_numpy()\n",
    "        self.labels = df['class'].to_numpy()\n",
    "        scaler = StandardScaler()\n",
    "        self.X_features = scaler.fit_transform(df[cols_mva])\n",
    "        \n",
    "        # Feel free to change these transforms! They are not optimal.\n",
    "        # You could also include e.g. RandomHorizontalFlip, RandomVerticalFlip\n",
    "        # for data augmentation.\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((128, 128)), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[94/255], std=[12/255]),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)   # you can limit the number of images by returning a smaller number here\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgpath = self.imgpaths[idx]\n",
    "        image = self.transform(Image.open(imgpath))        \n",
    "        \n",
    "        label = torch.tensor(self.labels[idx]).int()\n",
    "        xfeatures = torch.from_numpy(self.X_features[idx]).float()\n",
    "        \n",
    "        return image, label, xfeatures\n",
    "\n",
    "    \n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(ParticleDataset(train), batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(ParticleDataset(val), batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(ParticleDataset(test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have data loaders that can sample from our data. These can be used in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label, meta_features in dataloader_train:\n",
    "    print('Image batch shape =', img.shape)\n",
    "    print('Label batch shape =', label.shape)\n",
    "    print('Meta features batch shape =', meta_features.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running this cell many times -- new batches are generated each time:\n",
    "plt.figure(figsize=(7, 7))\n",
    "for img, label, meta_features in dataloader_train:\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(img[i, 0, :, :])\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Label = {int(label[i])}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example network:\n",
    "\n",
    "This network is rather small and does not include many of the features it potentially could (see exercise 1).\n",
    "\n",
    "Once again, try to draw the CNN, and think about how many parameters it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image size = 1 x 128 x 128  (1 channel, i.e. bw)\n",
    "net = nn.Sequential(nn.Conv2d(1, 3, 5),  # shape = (3, 124 x 124)\n",
    "                    nn.ReLU(),           # shape = (3, 124 x 124), see https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "                    nn.MaxPool2d(10),    # shape = (3, 12 x 12), see https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "                    nn.Flatten(),        # shape = (3 * 12 * 12) = (432)\n",
    "                    nn.Linear(432, 1),   # shape = (1)\n",
    "                    nn.Sigmoid())        # shape (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network takes a batch of images (batch x 1 x image_width x image_height) and returns a single number for each image (batch x 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label, meta_features in dataloader_train:\n",
    "    print(net(img).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to calculate shapes yourself. You can always ask with `.shape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have made this networks more explicitely by using a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool2d(10)\n",
    "        self.linear1 = nn.Linear(432, 1)\n",
    "        self.to_prop = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.nonlinearity(x)\n",
    "        x = self.mp1(x)\n",
    "        return self.to_prop(self.linear1(x.view(x.shape[0], -1)))\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label, meta_features in dataloader_train:\n",
    "    print(net(img).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two definitions are exactly the same, but, naturally, the latter is a lot more customizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to intepret the output of the model as being the probability of class 1. The `Sigmoid` at the end ensures that it is a number in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label, meta_features in dataloader_train:\n",
    "    output = net(img)\n",
    "    print(output.min(), output.max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example training routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of our model can be found using `.parameters()`. We make an optimizer and tell it to optimize over these paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(net.parameters(), lr=1e-4)  # lr = learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to use a GPU, if we have one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "print('Running on', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train we loop over epochs and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.BCELoss()\n",
    "for epoch in range(5):\n",
    "    acc_loss = 0.0\n",
    "    for img, label, meta_features in tqdm(dataloader_train, desc=f'Epoch {epoch + 1}'):\n",
    "        img = img.to(device)\n",
    "        output = net(img).squeeze()\n",
    "        label = label.float().to(device)\n",
    "        loss = loss_criterion(output, label)\n",
    "        loss.backward()  # calculate gradients: d Loss / d Paramters\n",
    "        opt.step()  # take a step down-hill\n",
    "        opt.zero_grad()  # zero the gradient calculations for next iteration\n",
    "        acc_loss += float(loss)\n",
    "    acc_loss /= len(dataloader_train)\n",
    "    print(f'Epoch {epoch + 1} loss = {acc_loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have trained a model, we should evaluate its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(model, dataset, only_img=True, only_meta=False):\n",
    "    acc = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for img, label, meta_features in dataset:\n",
    "            label = label.to(device)\n",
    "            img = img.to(device)\n",
    "            meta_features = meta_features.to(device)\n",
    "            \n",
    "            if only_img:\n",
    "                output = model(img).squeeze()\n",
    "            elif only_meta:\n",
    "                output = model(meta_features).squeeze()\n",
    "            else:\n",
    "                output = model(img, meta_features).squeeze()\n",
    "            \n",
    "            prediction = torch.round(output)\n",
    "            acc += torch.sum(torch.eq(prediction, label))\n",
    "            count += len(label)\n",
    "    return acc / count\n",
    "            \n",
    "print(f'Train accuracy = {float(calc_accuracy(net, dataloader_train))}')\n",
    "print(f'Test accuracy = {float(calc_accuracy(net, dataloader_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "The above model was okay, but not fantastic. Your job is to make a good CNN model. \n",
    "\n",
    "You should plot both the average loss and accuracy on both training and validation data as you train.\n",
    "Finally, evaluate your model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes to exercise 1\n",
    "\n",
    "Feel free to take inspiration from online examples. Some nice functions to use could be: `nn.Conv2d, nn.BatchNorm2d, nn.MaxPool2d, nn.Dropout...`.\n",
    "\n",
    "If you use `BatchNorm2d` and `Dropout`, you need to switch your network between train and evaluation mode appropriately: `net.train()`, `net.eval()`.\n",
    "\n",
    "In the current model, we use `nn.Sigmoid` at the end. This is a bit unstable, and it is smarter to simply omit this step and use `nn.BCEWithLogitsLoss()` instead of `nn.BCELoss()`.\n",
    "\n",
    "If you really want your model to perform, you can also use a pretrained model, e.g. `torchvision.models.resnet18`, as a backbone to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Make a model that uses the meta features instead of the images (possibly using PyTorch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label, meta_features in dataloader_train:\n",
    "    print(meta_features[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Combine your previous two models into one that uses both image and meta data. To do this, you should make a `Net(nn.Module)` class as demonstrated above. The `forward` function should then take both an image and a feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning points:\n",
    "\n",
    "This is a more involved CNN exercise than on the MNIST data, yet many of the learning points are the same:\n",
    "1. CNNs are the goto model for image analysis.\n",
    "2. They work by convoluting the input images with kernels that are trained to recognise certain features in the image (not unlike neurons in an ordinary NN).\n",
    "2. Your CNN considerations should include:\n",
    "     - Sample and image sizes (enough training and testing data?),\n",
    "     - CNN architecture (size and number of kernels),\n",
    "     - Batch size (optimising how fast you converge), and\n",
    "     - if you need GPUs for the problem!\n",
    "3. CNNs can be implemented in (Keras) TensorFlow (easiest) and PyTorch (harder but more versatile).\n",
    "\n",
    "One consideration that much can be learned from is asking yourself (and peers), if you could go through the above exercise using Keras TensorFlow? If this is the case, then you can at least claim good understanding of the CNN ingredients :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
